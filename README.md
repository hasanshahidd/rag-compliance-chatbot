<h2>ğŸ—‚ï¸ Project Structure</h2>
<pre class="project-structure"><code>
rag_compliance_chatbot/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ pdf_processing/       # PDF extraction & chunking
â”‚   â”‚   â”œâ”€â”€ extract_text.py   # Extracts text from PDFs (pdfplumber / PyPDF2 / OCR)
â”‚   â”‚   â”œâ”€â”€ chunk_text.py     # Splits text into structured chunks
â”‚   â”œâ”€â”€ rag_pipeline/         # RAG pipeline & retrieval
â”‚   â”‚   â”œâ”€â”€ embeddings.py     # Embeddings generation via SentenceTransformers
â”‚   â”‚   â”œâ”€â”€ vector_store.py   # Builds FAISS index
â”‚   â”‚   â”œâ”€â”€ query_engine.py   # Enhances query, retrieves chunks, generates response
â”‚   â”œâ”€â”€ compliance_analysis/  # Gap analysis & reporting
â”‚   â”‚   â”œâ”€â”€ report_generator.py # Generates compliance gap reports
â”‚   â”œâ”€â”€ ui/                   # Streamlit UI
â”‚   â”‚   â”œâ”€â”€ streamlit_app.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ input/                # PDF input
â”‚   â”‚   â”œâ”€â”€ information_security_policy_v4.0.pdf
â”‚   â”œâ”€â”€ knowledge_base/       # Indexed chunks
â”‚   â”‚   â”œâ”€â”€ index.faiss        # FAISS vector index
â”‚   â”‚   â”œâ”€â”€ chunks_structured.json
â”‚   â”œâ”€â”€ mappings/             # Compliance mapping
â”‚   â”‚   â”œâ”€â”€ compliance_mapping.json
â”‚   â”œâ”€â”€ reports/              # Generated gap reports
â”‚   â”‚   â”œâ”€â”€ gap_analysis_report.md
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.yaml           # Pipeline settings (chunk size, models, etc.)
â”‚   â”œâ”€â”€ compliance_rules.json # Compliance rules mapping
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_pdf_processing.py
â”‚   â”œâ”€â”€ test_rag_pipeline.py
â”‚   â”œâ”€â”€ test_compliance_analysis.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore                # Exclude .env, logs, virtualenv
â””â”€â”€ README.md                 # This overview
</code></pre>

<hr>

<h2>ğŸš€ Project Overview</h2>

<p><strong>RAG Compliance Chatbot</strong> is a Retrieval-Augmented Generation (RAG) system for analyzing text-based PDF policies (Information Security Policy v4.0) against <strong>PCI-DSS v3.2</strong> and <strong>ISO 27001:2013</strong>. It ingests PDFs, creates a knowledge base, retrieves relevant sections via semantic search, generates LLM-powered responses, and produces compliance gap reports.</p>

<ul>
  <li>PDF ingestion & chunking (~81k characters â†’ 251 structured chunks)</li>
  <li>FAISS vector store for similarity search</li>
  <li>Groq LLM (llama-3.1-8b-instant) with Hugging Face fallback</li>
  <li>PCI-DSS & ISO 27001 compliance mapping</li>
  <li>Compliance gap report generation</li>
  <li>Streamlit UI for query and report display</li>
</ul>

<hr>

<h2>âš™ï¸ Setup & Installation</h2>

<ol>
  <li><strong>Clone repository</strong>
    <pre><code>git clone https://github.com/your-org/rag_compliance_chatbot.git
cd rag_compliance_chatbot</code></pre>
  </li>
  <li><strong>Create virtual environment & activate</strong>
    <pre><code>python -m venv venv
# Windows
venv\Scripts\activate
# Linux/macOS
source venv/bin/activate</code></pre>
  </li>
  <li><strong>Install dependencies</strong>
    <pre><code>pip install -r requirements.txt</code></pre>
  </li>
  <li><strong>Configure environment variables</strong> in <code>.env</code> (excluded from Git):
    <pre><code>GROQ_API_KEY=your_groq_api_key</code></pre>
  </li>
  <li><strong>Configure pipeline</strong> in <code>config/config.yaml</code>:
    <pre><code>pdf_processing:
  chunk_size: 500
  embedding_model: 'sentence-transformers/all-MiniLM-L6-v2'
llm:
  model: 'distilbert-base-uncased'
  groq_api_key_env: 'GROQ_API_KEY'
vector_store:
  index_path: 'data/knowledge_base/index.faiss'</code></pre>
  </li>
</ol>

<hr>

<h2>ğŸ“„ PDF Processing & Knowledge Base</h2>

<ul>
  <li>Input: <code>information_security_policy_v4.0.pdf</code> (~81k characters)</li>
  <li>Extraction via <code>pdfplumber</code> / <code>PyPDF2</code> / OCR for scanned PDFs</li>
  <li>Chunking:
    <ul>
      <li>251 structured chunks (dictionary format: <code>{section, title, text}</code>)</li>
      <li>Each chunk used for semantic retrieval</li>
    </ul>
  </li>
</ul>

<pre><code>Total chunks: 251
1, Section 4.0: 68 words
2, Section 0: 7 words
3, Section 4.0: 18 words
...</code></pre>

<hr>

<h2>ğŸ’¾ FAISS Vector Store</h2>

<ul>
  <li>Embeddings: <code>SentenceTransformers('multi-qa-MiniLM-L6-cos-v1')</code></li>
  <li>Semantic search with FAISS for top-K chunks</li>
  <li>Deduplication ensures unique chunks in retrieval</li>
  <li>Enhances RAG LLM query response quality</li>
</ul>

<hr>

<h2>ğŸ¤– LLM Integration</h2>

<ul>
  <li>Primary: Groq LLM (<code>llama-3.1-8b-instant</code>)</li>
  <li>Fallback: Hugging Face QA (<code>distilbert-base-uncased-distilled-squad</code>)</li>
  <li>Query + retrieved chunks (truncated ~3000 tokens) â†’ LLM generates concise, professional answers (100â€“150 words)</li>
  <li>Inferred responses flagged with <code>[INFERRED]</code> if context insufficient</li>
</ul>

<hr>

<h2>ğŸ“ Compliance Gap Analysis</h2>

<ul>
  <li>Compares retrieved policy sections against PCI-DSS & ISO 27001</li>
  <li>Generates Markdown report with:
    <ul>
      <li>Compliance status</li>
      <li>Missing clauses</li>
      <li>Audit priority & risk levels</li>
      <li>Fallback notes for inferred answers</li>
    </ul>
  </li>
</ul>

<hr>

<h2>ğŸ–¥ï¸ Streamlit UI</h2>

<ul>
  <li>Query with policy questions (e.g., â€œWhat are the access control policies?â€)</li>
  <li>View responses + compliance gaps + audit priorities</li>
  <li>Export reports as Markdown</li>
  <li>Run: <code>streamlit run src/ui/streamlit_app.py</code></li>
</ul>

<hr>

<h2>ğŸ”§ Testing & Verification</h2>

<pre><code>pytest tests/unit/
pytest tests/integration/</code></pre>

<hr>

<h2>ğŸš« Files to Exclude (.gitignore)</h2>

<pre><code>.env
venv/
*.pyc
__pycache__/
data/reports/*
pipeline.log
</code></pre>

<hr>

<h2>ğŸ” Security & Privacy</h2>

<ul>
  <li>Environment variables store API keys (.env)</li>
  <li>User PDF data is processed locally; no sensitive data persisted</li>
  <li>Logs redact sensitive info</li>
</ul>

<hr>

<h2>ğŸ“ˆ Performance & Roadmap</h2>

<ul>
  <li>Chunking + FAISS + LLM allows fast semantic retrieval</li>
  <li>Future improvements:
    <ul>
      <li>Multi-PDF ingestion</li>
      <li>Interactive PDF/Excel exports</li>
      <li>Fine-tuned compliance LLM</li>
      <li>Enhanced UI/UX with HTML/CSS</li>
    </ul>
  </li>
</ul>

<hr>

<h2>ğŸ™ Acknowledgments</h2>

<p>Built with pdfplumber, PyPDF2, Tesseract OCR, SentenceTransformers, FAISS, Groq, Hugging Face, LangChain, Streamlit.</p>
